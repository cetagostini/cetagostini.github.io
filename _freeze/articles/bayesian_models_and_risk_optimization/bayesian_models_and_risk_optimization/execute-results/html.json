{
  "hash": "0c44e05bd27733e67f64a213291e2074",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Bayesian Models and Risk Optimization\"\ndate: \"2025-08-20\"\ncategories: [python, experimentation, media mix modeling, mmm, bayesian, pymc, pydata, germany, berlin]\nimage: \"../images/bayesian_models_and_risk_optimization.png\"\njupyter: cetagostini_web\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-overflow: wrap\n---\n\n# üìò Introduction\n\nThis article explores how Bayesian Media Mix Modeling (MMM) represents uncertainty and how we can optimize budget decisions under risk. We build a generative view of media response (carryover via adstock, diminishing returns via saturation, trend and seasonality) and use full posterior predictive distributions to compare allocations not only by expected outcomes but also by dispersion and tail risk.\n\nThis material accompanies my PyData Berlin 2025 talk, where I discuss practical risk-aware optimization for MMM: moving beyond mean-only plans to objectives that explicitly incorporate uncertainty‚Äîand how to communicate these trade-offs to stakeholders.\n\n# üì¶ Import libraries\n\n::: {#f203df05 .cell execution_count=1}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nfrom pymc_marketing.mmm.builders.yaml import build_mmm_from_yaml\nfrom pymc_marketing.mmm import GeometricAdstock, MichaelisMentenSaturation\nfrom pymc_marketing.mmm.budget_optimizer import optimizer_xarray_builder\nfrom pymc_marketing.mmm.multidimensional import (\n    MultiDimensionalBudgetOptimizerWrapper,\n)\nfrom pymc_marketing.prior import Prior\nfrom pymc_marketing.mmm import utility as ut\n\nfrom scipy import ndimage\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n```\n:::\n\n\n# ‚öôÔ∏è Notebook setup \n\n::: {#bcd9aa71 .cell execution_count=2}\n``` {.python .cell-code}\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.figsize\"] = [8, 4]\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"axes.labelsize\"] = 6\nplt.rcParams[\"xtick.labelsize\"] = 6\nplt.rcParams[\"ytick.labelsize\"] = 6\nplt.rcParams.update({\"figure.constrained_layout.use\": True})\n\n%load_ext autoreload\n%autoreload 2\n\nseed: int = sum(map(ord, \"pydata_berlin_2025\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\ndefault_figsize = (8, 4) # repeat to use later\n```\n:::\n\n\n# üß™ Data generation process\n\nThis section encodes a generative story for media response with clear uncertainty sources. We simulate outcomes as\n$$\ny_t = \\beta_0 + \\sum_{c} f(x_{c,t}; \\theta_c) + \\text{trend}_t + \\text{seasonality}_t + \\varepsilon_t\n$$\n\nwhere:\n\n- $y_t$ is the observed outcome (e.g., app installs or revenue) at time $t$\n- $\\beta_0$ is the baseline intercept\n- $f(x_{c,t}; \\theta_c)$ is the media response function for channel $c$ with spend $x_{c,t}$ and parameters $\\theta_c$.\n- $\\text{trend}_t$ captures long-term growth or decline patterns\n- $\\text{seasonality}_t$ models periodic effects (weekly, monthly patterns)\n- $\\varepsilon_t$ represents aleatoric uncertainty‚Äîirreducible noise from unobserved factors, measurement error, and inherent randomness that remains even with perfect knowledge of all parameters\n\nWe do not consider interactions; the causal DAG looks like this:\n\n::: {#60979bc9 .cell execution_count=3}\n``` {.python .cell-code}\nimport graphviz\n\ngraph = graphviz.Digraph()\ngraph.node(\"Media Spend\")\ngraph.node(\"Trend\", style=\"dashed\")\ngraph.node(\"Seasonality\", style=\"dashed\")\ngraph.node(\"Target\")\n\ngraph.edge(\"Media Spend\", \"Target\")\ngraph.edge(\"Trend\", \"Target\")\ngraph.edge(\"Seasonality\", \"Target\")\n\ngraph\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-4-output-1.svg){}\n:::\n:::\n\n\n## üìÜ Date range\nWe start by defining the date range.\n\n::: {#261e424d .cell execution_count=4}\n``` {.python .cell-code}\n# date range\nmin_date = pd.to_datetime(\"2024-09-01\")\nmax_date = pd.to_datetime(\"2025-09-01\")\n\ndf = pd.DataFrame(\n    data={\"date_week\": pd.date_range(start=min_date, end=max_date, freq=\"W-MON\")}\n)\n\nn = df.shape[0]\nprint(f\"Number of observations: {n}\")\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of observations: 53\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-09-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-09-09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-09-16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-09-23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-09-30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## üì£ Media data\n\n::: {#be8ef567 .cell execution_count=5}\n``` {.python .cell-code}\n# media data\nscaler_x1 = 300\nscaler_x2 = 280\nscaler_x3 = 50\nscaler_x4 = 100\ny_scaler = 1000\n\n# media data\nx1 = rng.uniform(low=0.0, high=1.0, size=n)\ndf[\"x1\"] = np.where(x1 > 0.8, x1, x1 / 2)\n\nx2 = rng.uniform(low=0.0, high=0.6, size=n)\ndf[\"x2\"] = np.where(x2 > 0.5, x2, 0)\n\nx3 = rng.uniform(low=0.0, high=0.8, size=n)\ndf[\"x3\"] = np.where(x3 > 0.7, x3, x3 / 6)\n\nx4 = rng.uniform(low=0.0, high=0.2, size=n)\ndf[\"x4\"] = np.where(x4 > 0.15, x4, x4 / 2)\n\n\nfig, ax = plt.subplots(\n    nrows=4, ncols=1, sharex=True, sharey=True, layout=\"constrained\"\n)\nsns.lineplot(x=\"date_week\", y=\"x1\", data=df, color=\"C0\", ax=ax[0])\nsns.lineplot(x=\"date_week\", y=\"x2\", data=df, color=\"C1\", ax=ax[1])\nsns.lineplot(x=\"date_week\", y=\"x3\", data=df, color=\"C2\", ax=ax[2])\nsns.lineplot(x=\"date_week\", y=\"x4\", data=df, color=\"C3\", ax=ax[3])\nax[3].set(xlabel=\"date\")\nfig.suptitle(\"Media Costs Data\", fontsize=16);\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-6-output-1.png){width=811 height=411}\n:::\n:::\n\n\n## üìà Trend and seasonality components\n\nWe define trend and seasonality. Seasonality follows a 4-week cycle modeled with a Fourier basis; trend is linear.\n\n::: {#471b48e0 .cell execution_count=6}\n``` {.python .cell-code}\n# Create Fourier components for monthly seasonality\nmonthly_period = 4  # 4-week cycle\nt = np.arange(n)\n\n# Create sin-cos signals for fourier components\nmonthly_sin = np.sin(2 * np.pi * t / monthly_period)\nmonthly_cos = np.cos(2 * np.pi * t / monthly_period)\n\n# Combine sin-cos to create the desired pattern\n# Use coefficients to shape the pattern\nmonthly_pattern = 0.6 * monthly_sin + 0.4 * monthly_cos\n\n# Apply smoothing using ndimage to reduce sharp transitions\nmonthly_pattern = ndimage.gaussian_filter1d(monthly_pattern, sigma=0.2)\n\n# Normalize to [-1, 1] range\nmonthly_pattern = (monthly_pattern / np.max(np.abs(monthly_pattern))) * .18\n\ndf[\"monthly_effect\"] = monthly_pattern\ndf[\"trend\"] = (np.linspace(start=0.0, stop=10, num=n) + 10) ** (1 / 8) - 1\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n\n# Plot monthly pattern\nax1.plot(df[\"date_week\"], monthly_pattern, label=\"Monthly Pattern (Smoothed)\", linewidth=2, color='blue')\nax1.set_ylabel(\"Pattern Value\")\nax1.set_title(\"Monthly Fourier Pattern (4-week cycle, Smoothed)\")\nax1.grid(True, alpha=0.3)\nax1.legend()\n\n# Plot trend\nax2.plot(df[\"date_week\"], df[\"trend\"], label=\"Trend\", linewidth=2, color='red')\nax2.set_xlabel(\"Date\")\nax2.set_ylabel(\"Trend Value\")\nax2.set_title(\"Linear Trend Component\")\nax2.grid(True, alpha=0.3)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-7-output-1.png){width=788 height=386}\n:::\n:::\n\n\n## üîÅ Adstock and saturation transformations\n\nFirst, we apply the adstock transformation to the media data.\n\n::: {#9e151a6f .cell execution_count=7}\n``` {.python .cell-code}\n# apply geometric adstock transformation\nalpha: float = 0.55\n\ndf[\"x1_adstock\"] = (\n    GeometricAdstock(l_max=8, normalize=True).function(x=df[\"x1\"].to_numpy(), alpha=alpha)\n    .eval()\n)\n\ndf[\"x2_adstock\"] = (\n    GeometricAdstock(l_max=8, normalize=True).function(x=df[\"x2\"].to_numpy(), alpha=alpha)\n    .eval()\n)\n\ndf[\"x3_adstock\"] = (\n    GeometricAdstock(l_max=8, normalize=True).function(x=df[\"x3\"].to_numpy(), alpha=alpha)\n    .eval()\n)\n\ndf[\"x4_adstock\"] = (\n    GeometricAdstock(l_max=8, normalize=True).function(x=df[\"x4\"].to_numpy(), alpha=alpha)\n    .eval()\n)\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_week</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>monthly_effect</th>\n      <th>trend</th>\n      <th>x1_adstock</th>\n      <th>x2_adstock</th>\n      <th>x3_adstock</th>\n      <th>x4_adstock</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-09-02</td>\n      <td>0.342627</td>\n      <td>0.581017</td>\n      <td>0.009625</td>\n      <td>0.072294</td>\n      <td>0.120001</td>\n      <td>0.333521</td>\n      <td>0.155484</td>\n      <td>0.263665</td>\n      <td>0.004368</td>\n      <td>0.032807</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-09-09</td>\n      <td>0.349177</td>\n      <td>0.000000</td>\n      <td>0.018831</td>\n      <td>0.007122</td>\n      <td>0.180000</td>\n      <td>0.336700</td>\n      <td>0.243973</td>\n      <td>0.145016</td>\n      <td>0.010948</td>\n      <td>0.021276</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-09-16</td>\n      <td>0.292217</td>\n      <td>0.000000</td>\n      <td>0.029268</td>\n      <td>0.011185</td>\n      <td>-0.120000</td>\n      <td>0.339827</td>\n      <td>0.266793</td>\n      <td>0.079759</td>\n      <td>0.019303</td>\n      <td>0.016778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-09-23</td>\n      <td>0.893449</td>\n      <td>0.000000</td>\n      <td>0.073220</td>\n      <td>0.056761</td>\n      <td>-0.180000</td>\n      <td>0.342904</td>\n      <td>0.552183</td>\n      <td>0.043867</td>\n      <td>0.043844</td>\n      <td>0.034986</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-09-30</td>\n      <td>0.197823</td>\n      <td>0.000000</td>\n      <td>0.073854</td>\n      <td>0.175182</td>\n      <td>0.120000</td>\n      <td>0.345932</td>\n      <td>0.393473</td>\n      <td>0.024127</td>\n      <td>0.057629</td>\n      <td>0.098740</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThen we apply the saturation transformation to the adstock transformed media data.\n\n::: {#26fe260c .cell execution_count=8}\n``` {.python .cell-code}\nalpha_sat_x1: float = 0.3\nlam_sat_x1: float = 1.1\n\nalpha_sat_x2: float = 0.1\nlam_sat_x2: float = 1.5\n\nalpha_sat_x3: float = 0.2\nlam_sat_x3: float = 0.3\n\nalpha_sat_x4: float = 0.8\nlam_sat_x4: float = 0.8\n\ndf[\"x1_adstock_saturated\"] = (\n    MichaelisMentenSaturation().function(\n        x=df[\"x1_adstock\"].to_numpy(),\n        alpha=alpha_sat_x1,\n        lam=lam_sat_x1,\n    ).eval()\n)\n\ndf[\"x2_adstock_saturated\"] = (\n    MichaelisMentenSaturation().function(\n        x=df[\"x2_adstock\"].to_numpy(),\n        alpha=alpha_sat_x2,\n        lam=lam_sat_x2,\n    ).eval()\n)\n\ndf[\"x3_adstock_saturated\"] = (\n    MichaelisMentenSaturation().function(\n        x=df[\"x3_adstock\"].to_numpy(),  \n        alpha=alpha_sat_x3,\n        lam=lam_sat_x3,\n    ).eval()\n)\n\ndf[\"x4_adstock_saturated\"] = (\n    MichaelisMentenSaturation().function(\n        x=df[\"x4_adstock\"].to_numpy(),\n        alpha=alpha_sat_x4,\n        lam=lam_sat_x4,\n    ).eval()\n)\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_week</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>monthly_effect</th>\n      <th>trend</th>\n      <th>x1_adstock</th>\n      <th>x2_adstock</th>\n      <th>x3_adstock</th>\n      <th>x4_adstock</th>\n      <th>x1_adstock_saturated</th>\n      <th>x2_adstock_saturated</th>\n      <th>x3_adstock_saturated</th>\n      <th>x4_adstock_saturated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-09-02</td>\n      <td>0.342627</td>\n      <td>0.581017</td>\n      <td>0.009625</td>\n      <td>0.072294</td>\n      <td>0.120001</td>\n      <td>0.333521</td>\n      <td>0.155484</td>\n      <td>0.263665</td>\n      <td>0.004368</td>\n      <td>0.032807</td>\n      <td>0.037153</td>\n      <td>0.014950</td>\n      <td>0.002870</td>\n      <td>0.031515</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-09-09</td>\n      <td>0.349177</td>\n      <td>0.000000</td>\n      <td>0.018831</td>\n      <td>0.007122</td>\n      <td>0.180000</td>\n      <td>0.336700</td>\n      <td>0.243973</td>\n      <td>0.145016</td>\n      <td>0.010948</td>\n      <td>0.021276</td>\n      <td>0.054459</td>\n      <td>0.008815</td>\n      <td>0.007042</td>\n      <td>0.020725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-09-16</td>\n      <td>0.292217</td>\n      <td>0.000000</td>\n      <td>0.029268</td>\n      <td>0.011185</td>\n      <td>-0.120000</td>\n      <td>0.339827</td>\n      <td>0.266793</td>\n      <td>0.079759</td>\n      <td>0.019303</td>\n      <td>0.016778</td>\n      <td>0.058559</td>\n      <td>0.005049</td>\n      <td>0.012091</td>\n      <td>0.016433</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-09-23</td>\n      <td>0.893449</td>\n      <td>0.000000</td>\n      <td>0.073220</td>\n      <td>0.056761</td>\n      <td>-0.180000</td>\n      <td>0.342904</td>\n      <td>0.552183</td>\n      <td>0.043867</td>\n      <td>0.043844</td>\n      <td>0.034986</td>\n      <td>0.100264</td>\n      <td>0.002841</td>\n      <td>0.025502</td>\n      <td>0.033520</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-09-30</td>\n      <td>0.197823</td>\n      <td>0.000000</td>\n      <td>0.073854</td>\n      <td>0.175182</td>\n      <td>0.120000</td>\n      <td>0.345932</td>\n      <td>0.393473</td>\n      <td>0.024127</td>\n      <td>0.057629</td>\n      <td>0.098740</td>\n      <td>0.079038</td>\n      <td>0.001583</td>\n      <td>0.032228</td>\n      <td>0.087892</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLet's visualize how the media data look after adstock and saturation, and how they translate into units of Y (app installs or revenue).\n\n::: {#9b3455cf .cell execution_count=9}\n``` {.python .cell-code}\nfig, ax = plt.subplots(\n    nrows=3, ncols=4, sharex=True, sharey=False, layout=\"constrained\"\n)\nsns.lineplot(x=\"date_week\", y=\"x1\", data=df, color=\"C0\", ax=ax[0, 0])\nsns.lineplot(x=\"date_week\", y=\"x2\", data=df, color=\"C1\", ax=ax[0, 1])\nsns.lineplot(x=\"date_week\", y=\"x1_adstock\", data=df, color=\"C0\", ax=ax[1, 0])\nsns.lineplot(x=\"date_week\", y=\"x2_adstock\", data=df, color=\"C1\", ax=ax[1, 1])\nsns.lineplot(x=\"date_week\", y=\"x1_adstock_saturated\", data=df, color=\"C0\", ax=ax[2, 0])\nsns.lineplot(x=\"date_week\", y=\"x2_adstock_saturated\", data=df, color=\"C1\", ax=ax[2, 1])\nsns.lineplot(x=\"date_week\", y=\"x3\", data=df, color=\"C2\", ax=ax[0, 2])\nsns.lineplot(x=\"date_week\", y=\"x3_adstock\", data=df, color=\"C2\", ax=ax[1, 2])\nsns.lineplot(x=\"date_week\", y=\"x3_adstock_saturated\", data=df, color=\"C2\", ax=ax[2, 2])\nsns.lineplot(x=\"date_week\", y=\"x4\", data=df, color=\"C3\", ax=ax[0, 3])\nsns.lineplot(x=\"date_week\", y=\"x4_adstock\", data=df, color=\"C3\", ax=ax[1, 3])\nsns.lineplot(x=\"date_week\", y=\"x4_adstock_saturated\", data=df, color=\"C3\", ax=ax[2, 3])\nfig.suptitle(\"Media Costs Data - Transformed\", fontsize=16);\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-10-output-1.png){width=811 height=411}\n:::\n:::\n\n\nWe now add the intercept and noise, and sum the transformed media, trend, and seasonality components.\n\n::: {#7ebab71f .cell execution_count=10}\n``` {.python .cell-code}\ndf[\"intercept\"] = 0.15\ndf[\"epsilon\"] = rng.normal(loc=0.0, scale=0.075, size=n)\n\ndf[\"app_installs\"] = df[[\"intercept\", \"x1_adstock_saturated\", \"x2_adstock_saturated\", \"x3_adstock_saturated\", \"x4_adstock_saturated\", \"trend\", \"monthly_effect\", \"epsilon\"]].sum(axis=1)\ndf[\"app_installs\"] *= y_scaler\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_week</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>monthly_effect</th>\n      <th>trend</th>\n      <th>x1_adstock</th>\n      <th>x2_adstock</th>\n      <th>x3_adstock</th>\n      <th>x4_adstock</th>\n      <th>x1_adstock_saturated</th>\n      <th>x2_adstock_saturated</th>\n      <th>x3_adstock_saturated</th>\n      <th>x4_adstock_saturated</th>\n      <th>intercept</th>\n      <th>epsilon</th>\n      <th>app_installs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-09-02</td>\n      <td>0.342627</td>\n      <td>0.581017</td>\n      <td>0.009625</td>\n      <td>0.072294</td>\n      <td>0.120001</td>\n      <td>0.333521</td>\n      <td>0.155484</td>\n      <td>0.263665</td>\n      <td>0.004368</td>\n      <td>0.032807</td>\n      <td>0.037153</td>\n      <td>0.014950</td>\n      <td>0.002870</td>\n      <td>0.031515</td>\n      <td>0.15</td>\n      <td>0.154459</td>\n      <td>844.469551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-09-09</td>\n      <td>0.349177</td>\n      <td>0.000000</td>\n      <td>0.018831</td>\n      <td>0.007122</td>\n      <td>0.180000</td>\n      <td>0.336700</td>\n      <td>0.243973</td>\n      <td>0.145016</td>\n      <td>0.010948</td>\n      <td>0.021276</td>\n      <td>0.054459</td>\n      <td>0.008815</td>\n      <td>0.007042</td>\n      <td>0.020725</td>\n      <td>0.15</td>\n      <td>0.177488</td>\n      <td>935.229200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-09-16</td>\n      <td>0.292217</td>\n      <td>0.000000</td>\n      <td>0.029268</td>\n      <td>0.011185</td>\n      <td>-0.120000</td>\n      <td>0.339827</td>\n      <td>0.266793</td>\n      <td>0.079759</td>\n      <td>0.019303</td>\n      <td>0.016778</td>\n      <td>0.058559</td>\n      <td>0.005049</td>\n      <td>0.012091</td>\n      <td>0.016433</td>\n      <td>0.15</td>\n      <td>0.052790</td>\n      <td>514.748757</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-09-23</td>\n      <td>0.893449</td>\n      <td>0.000000</td>\n      <td>0.073220</td>\n      <td>0.056761</td>\n      <td>-0.180000</td>\n      <td>0.342904</td>\n      <td>0.552183</td>\n      <td>0.043867</td>\n      <td>0.043844</td>\n      <td>0.034986</td>\n      <td>0.100264</td>\n      <td>0.002841</td>\n      <td>0.025502</td>\n      <td>0.033520</td>\n      <td>0.15</td>\n      <td>-0.034546</td>\n      <td>440.486094</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-09-30</td>\n      <td>0.197823</td>\n      <td>0.000000</td>\n      <td>0.073854</td>\n      <td>0.175182</td>\n      <td>0.120000</td>\n      <td>0.345932</td>\n      <td>0.393473</td>\n      <td>0.024127</td>\n      <td>0.057629</td>\n      <td>0.098740</td>\n      <td>0.079038</td>\n      <td>0.001583</td>\n      <td>0.032228</td>\n      <td>0.087892</td>\n      <td>0.15</td>\n      <td>0.090876</td>\n      <td>907.549889</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis is how the target looks.\n\n::: {#555b238e .cell execution_count=11}\n``` {.python .cell-code}\ndf.set_index(\"date_week\").app_installs.plot();\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-12-output-1.png){width=811 height=411}\n:::\n:::\n\n\nWe also add the original media to the DataFrame so we can visualize it before any transformations and use it as model input.\n\n::: {#540ad02d .cell execution_count=12}\n``` {.python .cell-code}\ndf[[\"x1_original_scale\", \"x2_original_scale\", \"x3_original_scale\", \"x4_original_scale\"]] = df[[\"x1\", \"x2\", \"x3\", \"x4\"]]\ndf[\"x1_original_scale\"] *= scaler_x1\ndf[\"x2_original_scale\"] *= scaler_x2\ndf[\"x3_original_scale\"] *= scaler_x3\ndf[\"x4_original_scale\"] *= scaler_x4\n\ndf[[\"date_week\", \"x1_original_scale\", \"x2_original_scale\", \"x3_original_scale\", \"app_installs\"]].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_week</th>\n      <th>x1_original_scale</th>\n      <th>x2_original_scale</th>\n      <th>x3_original_scale</th>\n      <th>app_installs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-09-02</td>\n      <td>102.788211</td>\n      <td>162.684671</td>\n      <td>0.481258</td>\n      <td>844.469551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-09-09</td>\n      <td>104.753127</td>\n      <td>0.000000</td>\n      <td>0.941552</td>\n      <td>935.229200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-09-16</td>\n      <td>87.665114</td>\n      <td>0.000000</td>\n      <td>1.463382</td>\n      <td>514.748757</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-09-23</td>\n      <td>268.034637</td>\n      <td>0.000000</td>\n      <td>3.661005</td>\n      <td>440.486094</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-09-30</td>\n      <td>59.346861</td>\n      <td>0.000000</td>\n      <td>3.692695</td>\n      <td>907.549889</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# üèóÔ∏è Building the model\n\nThe YAML configuration encodes a fully Bayesian MMM with priors over the core response mechanics and temporal structure. For model specifics and worked examples, see the PyMC‚ÄëMarketing [Example Gallery](https://www.pymc-marketing.io/en/stable/gallery/gallery.html) and [API](https://www.pymc-marketing.io/en/stable/api/index.html).\n\nHere we split the data into train and test sets. Not to evaluate the fit; instead, we use the test set to compare the results of the optimization, checking if it will be \"better\" than the budget recommendations.\n\n::: {#175dda23 .cell execution_count=13}\n``` {.python .cell-code}\ndf_train = df.query(\"date_week <= '2025-08-30'\").copy()\nx_train = df_train[[\"date_week\", \"x1_original_scale\", \"x2_original_scale\", \"x3_original_scale\", \"x4_original_scale\"]]\ny_train = df_train[\"app_installs\"]\n\ndf_test = df.query(\"date_week > '2025-08-30'\").copy()\nx_test = df_test[[\"date_week\", \"x1_original_scale\", \"x2_original_scale\", \"x3_original_scale\", \"x4_original_scale\"]]\ny_test = df_test[\"app_installs\"]\n```\n:::\n\n\nBecause the model was defined previously in the YAML, building it is straightforward and takes only a few lines.\n\n::: {#418bf1b2 .cell execution_count=14}\n``` {.python .cell-code}\nmmm = build_mmm_from_yaml(\n    X=x_train,\n    y=y_train,\n    config_path=\"pymc_model.yml\",\n)\n```\n:::\n\n\nNow we fit the model and check convergence.\n\n::: {#a0a2976e .cell execution_count=15}\n``` {.python .cell-code}\nmmm.fit(\n    X=x_train,\n    y=y_train,\n    random_seed=rng,\n)\n\nmmm.sample_posterior_predictive(\n    X=x_train,\n    extend_idata=True,\n    combined=True,\n    random_seed=rng,\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    :root {\n        --column-width-1: 40%; /* Progress column width */\n        --column-width-2: 15%; /* Chain column width */\n        --column-width-3: 15%; /* Divergences column width */\n        --column-width-4: 15%; /* Step Size column width */\n        --column-width-5: 15%; /* Gradients/Draw column width */\n    }\n\n    .nutpie {\n        max-width: 800px;\n        margin: 10px auto;\n        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n        //color: #333;\n        //background-color: #fff;\n        padding: 10px;\n        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n        border-radius: 8px;\n        font-size: 14px; /* Smaller font size for a more compact look */\n    }\n    .nutpie table {\n        width: 100%;\n        border-collapse: collapse; /* Remove any extra space between borders */\n    }\n    .nutpie th, .nutpie td {\n        padding: 8px 10px; /* Reduce padding to make table more compact */\n        text-align: left;\n        border-bottom: 1px solid #888;\n    }\n    .nutpie th {\n        //background-color: #f0f0f0;\n    }\n\n    .nutpie th:nth-child(1) { width: var(--column-width-1); }\n    .nutpie th:nth-child(2) { width: var(--column-width-2); }\n    .nutpie th:nth-child(3) { width: var(--column-width-3); }\n    .nutpie th:nth-child(4) { width: var(--column-width-4); }\n    .nutpie th:nth-child(5) { width: var(--column-width-5); }\n\n    .nutpie progress {\n        width: 100%;\n        height: 15px; /* Smaller progress bars */\n        border-radius: 5px;\n    }\n    progress::-webkit-progress-bar {\n        background-color: #eee;\n        border-radius: 5px;\n    }\n    progress::-webkit-progress-value {\n        background-color: #5cb85c;\n        border-radius: 5px;\n    }\n    progress::-moz-progress-bar {\n        background-color: #5cb85c;\n        border-radius: 5px;\n    }\n    .nutpie .progress-cell {\n        width: 100%;\n    }\n\n    .nutpie p strong { font-size: 16px; font-weight: bold; }\n\n    @media (prefers-color-scheme: dark) {\n        .nutpie {\n            //color: #ddd;\n            //background-color: #1e1e1e;\n            box-shadow: 0 4px 6px rgba(0,0,0,0.2);\n        }\n        .nutpie table, .nutpie th, .nutpie td {\n            border-color: #555;\n            color: #ccc;\n        }\n        .nutpie th {\n            background-color: #2a2a2a;\n        }\n        .nutpie progress::-webkit-progress-bar {\n            background-color: #444;\n        }\n        .nutpie progress::-webkit-progress-value {\n            background-color: #3178c6;\n        }\n        .nutpie progress::-moz-progress-bar {\n            background-color: #3178c6;\n        }\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<div class=\"nutpie\">\n    <p><strong>Sampler Progress</strong></p>\n    <p>Total Chains: <span id=\"total-chains\">4</span></p>\n    <p>Active Chains: <span id=\"active-chains\">0</span></p>\n    <p>\n        Finished Chains:\n        <span id=\"active-chains\">4</span>\n    </p>\n    <p>Sampling for now</p>\n    <p>\n        Estimated Time to Completion:\n        <span id=\"eta\">now</span>\n    </p>\n\n    <progress\n        id=\"total-progress-bar\"\n        max=\"5200\"\n        value=\"5200\">\n    </progress>\n    <table>\n        <thead>\n            <tr>\n                <th>Progress</th>\n                <th>Draws</th>\n                <th>Divergences</th>\n                <th>Step Size</th>\n                <th>Gradients/Draw</th>\n            </tr>\n        </thead>\n        <tbody id=\"chain-details\">\n            \n                <tr>\n                    <td class=\"progress-cell\">\n                        <progress\n                            max=\"1300\"\n                            value=\"1300\">\n                        </progress>\n                    </td>\n                    <td>1300</td>\n                    <td>0</td>\n                    <td>0.11</td>\n                    <td>31</td>\n                </tr>\n            \n                <tr>\n                    <td class=\"progress-cell\">\n                        <progress\n                            max=\"1300\"\n                            value=\"1300\">\n                        </progress>\n                    </td>\n                    <td>1300</td>\n                    <td>0</td>\n                    <td>0.10</td>\n                    <td>63</td>\n                </tr>\n            \n                <tr>\n                    <td class=\"progress-cell\">\n                        <progress\n                            max=\"1300\"\n                            value=\"1300\">\n                        </progress>\n                    </td>\n                    <td>1300</td>\n                    <td>0</td>\n                    <td>0.11</td>\n                    <td>31</td>\n                </tr>\n            \n                <tr>\n                    <td class=\"progress-cell\">\n                        <progress\n                            max=\"1300\"\n                            value=\"1300\">\n                        </progress>\n                    </td>\n                    <td>1300</td>\n                    <td>0</td>\n                    <td>0.11</td>\n                    <td>31</td>\n                </tr>\n            \n            </tr>\n        </tbody>\n    </table>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"a29ec3ab594c4dccab6d509e20f03cbe\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"59c5c13bb940459cb77f52a0b3a92ba0\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n<defs>\n<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n</symbol>\n<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n</symbol>\n</defs>\n</svg>\n<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n *\n */\n\n:root {\n  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n  --xr-background-color: var(--jp-layout-color0, white);\n  --xr-background-color-row-even: var(--jp-layout-color1, white);\n  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n}\n\nhtml[theme=\"dark\"],\nhtml[data-theme=\"dark\"],\nbody[data-theme=\"dark\"],\nbody.vscode-dark {\n  --xr-font-color0: rgba(255, 255, 255, 1);\n  --xr-font-color2: rgba(255, 255, 255, 0.54);\n  --xr-font-color3: rgba(255, 255, 255, 0.38);\n  --xr-border-color: #1f1f1f;\n  --xr-disabled-color: #515151;\n  --xr-background-color: #111111;\n  --xr-background-color-row-even: #111111;\n  --xr-background-color-row-odd: #313131;\n}\n\n.xr-wrap {\n  display: block !important;\n  min-width: 300px;\n  max-width: 700px;\n}\n\n.xr-text-repr-fallback {\n  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n  display: none;\n}\n\n.xr-header {\n  padding-top: 6px;\n  padding-bottom: 6px;\n  margin-bottom: 4px;\n  border-bottom: solid 1px var(--xr-border-color);\n}\n\n.xr-header > div,\n.xr-header > ul {\n  display: inline;\n  margin-top: 0;\n  margin-bottom: 0;\n}\n\n.xr-obj-type,\n.xr-array-name {\n  margin-left: 2px;\n  margin-right: 10px;\n}\n\n.xr-obj-type {\n  color: var(--xr-font-color2);\n}\n\n.xr-sections {\n  padding-left: 0 !important;\n  display: grid;\n  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n}\n\n.xr-section-item {\n  display: contents;\n}\n\n.xr-section-item input {\n  display: inline-block;\n  opacity: 0;\n  height: 0;\n}\n\n.xr-section-item input + label {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-item input:enabled + label {\n  cursor: pointer;\n  color: var(--xr-font-color2);\n}\n\n.xr-section-item input:focus + label {\n  border: 2px solid var(--xr-font-color0);\n}\n\n.xr-section-item input:enabled + label:hover {\n  color: var(--xr-font-color0);\n}\n\n.xr-section-summary {\n  grid-column: 1;\n  color: var(--xr-font-color2);\n  font-weight: 500;\n}\n\n.xr-section-summary > span {\n  display: inline-block;\n  padding-left: 0.5em;\n}\n\n.xr-section-summary-in:disabled + label {\n  color: var(--xr-font-color2);\n}\n\n.xr-section-summary-in + label:before {\n  display: inline-block;\n  content: \"‚ñ∫\";\n  font-size: 11px;\n  width: 15px;\n  text-align: center;\n}\n\n.xr-section-summary-in:disabled + label:before {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-summary-in:checked + label:before {\n  content: \"‚ñº\";\n}\n\n.xr-section-summary-in:checked + label > span {\n  display: none;\n}\n\n.xr-section-summary,\n.xr-section-inline-details {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n.xr-section-inline-details {\n  grid-column: 2 / -1;\n}\n\n.xr-section-details {\n  display: none;\n  grid-column: 1 / -1;\n  margin-bottom: 5px;\n}\n\n.xr-section-summary-in:checked ~ .xr-section-details {\n  display: contents;\n}\n\n.xr-array-wrap {\n  grid-column: 1 / -1;\n  display: grid;\n  grid-template-columns: 20px auto;\n}\n\n.xr-array-wrap > label {\n  grid-column: 1;\n  vertical-align: top;\n}\n\n.xr-preview {\n  color: var(--xr-font-color3);\n}\n\n.xr-array-preview,\n.xr-array-data {\n  padding: 0 5px !important;\n  grid-column: 2;\n}\n\n.xr-array-data,\n.xr-array-in:checked ~ .xr-array-preview {\n  display: none;\n}\n\n.xr-array-in:checked ~ .xr-array-data,\n.xr-array-preview {\n  display: inline-block;\n}\n\n.xr-dim-list {\n  display: inline-block !important;\n  list-style: none;\n  padding: 0 !important;\n  margin: 0;\n}\n\n.xr-dim-list li {\n  display: inline-block;\n  padding: 0;\n  margin: 0;\n}\n\n.xr-dim-list:before {\n  content: \"(\";\n}\n\n.xr-dim-list:after {\n  content: \")\";\n}\n\n.xr-dim-list li:not(:last-child):after {\n  content: \",\";\n  padding-right: 5px;\n}\n\n.xr-has-index {\n  font-weight: bold;\n}\n\n.xr-var-list,\n.xr-var-item {\n  display: contents;\n}\n\n.xr-var-item > div,\n.xr-var-item label,\n.xr-var-item > .xr-var-name span {\n  background-color: var(--xr-background-color-row-even);\n  margin-bottom: 0;\n}\n\n.xr-var-item > .xr-var-name:hover span {\n  padding-right: 5px;\n}\n\n.xr-var-list > li:nth-child(odd) > div,\n.xr-var-list > li:nth-child(odd) > label,\n.xr-var-list > li:nth-child(odd) > .xr-var-name span {\n  background-color: var(--xr-background-color-row-odd);\n}\n\n.xr-var-name {\n  grid-column: 1;\n}\n\n.xr-var-dims {\n  grid-column: 2;\n}\n\n.xr-var-dtype {\n  grid-column: 3;\n  text-align: right;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-preview {\n  grid-column: 4;\n}\n\n.xr-index-preview {\n  grid-column: 2 / 5;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-name,\n.xr-var-dims,\n.xr-var-dtype,\n.xr-preview,\n.xr-attrs dt {\n  white-space: nowrap;\n  overflow: hidden;\n  text-overflow: ellipsis;\n  padding-right: 10px;\n}\n\n.xr-var-name:hover,\n.xr-var-dims:hover,\n.xr-var-dtype:hover,\n.xr-attrs dt:hover {\n  overflow: visible;\n  width: auto;\n  z-index: 1;\n}\n\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  display: none;\n  background-color: var(--xr-background-color) !important;\n  padding-bottom: 5px !important;\n}\n\n.xr-var-attrs-in:checked ~ .xr-var-attrs,\n.xr-var-data-in:checked ~ .xr-var-data,\n.xr-index-data-in:checked ~ .xr-index-data {\n  display: block;\n}\n\n.xr-var-data > table {\n  float: right;\n}\n\n.xr-var-name span,\n.xr-var-data,\n.xr-index-name div,\n.xr-index-data,\n.xr-attrs {\n  padding-left: 25px !important;\n}\n\n.xr-attrs,\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  grid-column: 1 / -1;\n}\n\ndl.xr-attrs {\n  padding: 0;\n  margin: 0;\n  display: grid;\n  grid-template-columns: 125px auto;\n}\n\n.xr-attrs dt,\n.xr-attrs dd {\n  padding: 0;\n  margin: 0;\n  float: left;\n  padding-right: 10px;\n  width: auto;\n}\n\n.xr-attrs dt {\n  font-weight: normal;\n  grid-column: 1;\n}\n\n.xr-attrs dt:hover span {\n  display: inline-block;\n  background: var(--xr-background-color);\n  padding-right: 10px;\n}\n\n.xr-attrs dd {\n  grid-column: 2;\n  white-space: pre-wrap;\n  word-break: break-all;\n}\n\n.xr-icon-database,\n.xr-icon-file-text2,\n.xr-no-icon {\n  display: inline-block;\n  vertical-align: middle;\n  width: 1em;\n  height: 1.5em !important;\n  stroke-width: 0;\n  stroke: currentColor;\n  fill: currentColor;\n}\n</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 2MB\nDimensions:           (date: 52, sample: 2000)\nCoordinates:\n  * date              (date) datetime64[ns] 416B 2024-09-02 ... 2025-08-25\n  * sample            (sample) object 16kB MultiIndex\n  * chain             (sample) int64 16kB 0 0 0 0 0 0 0 0 0 ... 3 3 3 3 3 3 3 3\n  * draw              (sample) int64 16kB 0 1 2 3 4 5 ... 495 496 497 498 499\nData variables:\n    y                 (date, sample) float64 832kB 1.1 1.482 ... 1.375 0.03829\n    y_original_scale  (date, sample) float64 832kB 1.095e+03 1.475e+03 ... 38.1\nAttributes:\n    created_at:                 2025-08-23T19:04:45.359585+00:00\n    arviz_version:              0.21.0\n    inference_library:          pymc\n    inference_library_version:  5.25.1</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-f2d94998-4342-41b6-bfdf-fe1f49961ce3' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f2d94998-4342-41b6-bfdf-fe1f49961ce3' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>date</span>: 52</li><li><span class='xr-has-index'>sample</span>: 2000</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-040cb0bb-5308-42f0-b95b-4be7ccb781ad' class='xr-section-summary-in' type='checkbox'  checked><label for='section-040cb0bb-5308-42f0-b95b-4be7ccb781ad' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>date</span></div><div class='xr-var-dims'>(date)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2024-09-02 ... 2025-08-25</div><input id='attrs-d6e06196-c441-464f-b2ce-92768b993991' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d6e06196-c441-464f-b2ce-92768b993991' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6963ae92-d556-4d0c-9160-99233cbbdb1c' class='xr-var-data-in' type='checkbox'><label for='data-6963ae92-d556-4d0c-9160-99233cbbdb1c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2024-09-02T00:00:00.000000000&#x27;, &#x27;2024-09-09T00:00:00.000000000&#x27;,\n       &#x27;2024-09-16T00:00:00.000000000&#x27;, &#x27;2024-09-23T00:00:00.000000000&#x27;,\n       &#x27;2024-09-30T00:00:00.000000000&#x27;, &#x27;2024-10-07T00:00:00.000000000&#x27;,\n       &#x27;2024-10-14T00:00:00.000000000&#x27;, &#x27;2024-10-21T00:00:00.000000000&#x27;,\n       &#x27;2024-10-28T00:00:00.000000000&#x27;, &#x27;2024-11-04T00:00:00.000000000&#x27;,\n       &#x27;2024-11-11T00:00:00.000000000&#x27;, &#x27;2024-11-18T00:00:00.000000000&#x27;,\n       &#x27;2024-11-25T00:00:00.000000000&#x27;, &#x27;2024-12-02T00:00:00.000000000&#x27;,\n       &#x27;2024-12-09T00:00:00.000000000&#x27;, &#x27;2024-12-16T00:00:00.000000000&#x27;,\n       &#x27;2024-12-23T00:00:00.000000000&#x27;, &#x27;2024-12-30T00:00:00.000000000&#x27;,\n       &#x27;2025-01-06T00:00:00.000000000&#x27;, &#x27;2025-01-13T00:00:00.000000000&#x27;,\n       &#x27;2025-01-20T00:00:00.000000000&#x27;, &#x27;2025-01-27T00:00:00.000000000&#x27;,\n       &#x27;2025-02-03T00:00:00.000000000&#x27;, &#x27;2025-02-10T00:00:00.000000000&#x27;,\n       &#x27;2025-02-17T00:00:00.000000000&#x27;, &#x27;2025-02-24T00:00:00.000000000&#x27;,\n       &#x27;2025-03-03T00:00:00.000000000&#x27;, &#x27;2025-03-10T00:00:00.000000000&#x27;,\n       &#x27;2025-03-17T00:00:00.000000000&#x27;, &#x27;2025-03-24T00:00:00.000000000&#x27;,\n       &#x27;2025-03-31T00:00:00.000000000&#x27;, &#x27;2025-04-07T00:00:00.000000000&#x27;,\n       &#x27;2025-04-14T00:00:00.000000000&#x27;, &#x27;2025-04-21T00:00:00.000000000&#x27;,\n       &#x27;2025-04-28T00:00:00.000000000&#x27;, &#x27;2025-05-05T00:00:00.000000000&#x27;,\n       &#x27;2025-05-12T00:00:00.000000000&#x27;, &#x27;2025-05-19T00:00:00.000000000&#x27;,\n       &#x27;2025-05-26T00:00:00.000000000&#x27;, &#x27;2025-06-02T00:00:00.000000000&#x27;,\n       &#x27;2025-06-09T00:00:00.000000000&#x27;, &#x27;2025-06-16T00:00:00.000000000&#x27;,\n       &#x27;2025-06-23T00:00:00.000000000&#x27;, &#x27;2025-06-30T00:00:00.000000000&#x27;,\n       &#x27;2025-07-07T00:00:00.000000000&#x27;, &#x27;2025-07-14T00:00:00.000000000&#x27;,\n       &#x27;2025-07-21T00:00:00.000000000&#x27;, &#x27;2025-07-28T00:00:00.000000000&#x27;,\n       &#x27;2025-08-04T00:00:00.000000000&#x27;, &#x27;2025-08-11T00:00:00.000000000&#x27;,\n       &#x27;2025-08-18T00:00:00.000000000&#x27;, &#x27;2025-08-25T00:00:00.000000000&#x27;],\n      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>sample</span></div><div class='xr-var-dims'>(sample)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>MultiIndex</div><input id='attrs-9178739a-1e5d-4caa-b597-e7aa6f45b3fa' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9178739a-1e5d-4caa-b597-e7aa6f45b3fa' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-de1833e6-1705-4186-a6d2-617b14aa6aa0' class='xr-var-data-in' type='checkbox'><label for='data-de1833e6-1705-4186-a6d2-617b14aa6aa0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([(0, 0), (0, 1), (0, 2), ..., (3, 497), (3, 498), (3, 499)], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>chain</span></div><div class='xr-var-dims'>(sample)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 0 0 0 0 0 0 0 ... 3 3 3 3 3 3 3 3</div><input id='attrs-497640b0-7406-4349-aa7c-08212f244d20' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-497640b0-7406-4349-aa7c-08212f244d20' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0657bdb3-1bdf-42ee-aa5e-c2067e0c991d' class='xr-var-data-in' type='checkbox'><label for='data-0657bdb3-1bdf-42ee-aa5e-c2067e0c991d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 0, 0, ..., 3, 3, 3])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>draw</span></div><div class='xr-var-dims'>(sample)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 ... 495 496 497 498 499</div><input id='attrs-c813f7a4-6ea3-4896-823a-fbf016f5606a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c813f7a4-6ea3-4896-823a-fbf016f5606a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-691825b4-8df1-4e61-95d7-f94b6f2476d4' class='xr-var-data-in' type='checkbox'><label for='data-691825b4-8df1-4e61-95d7-f94b6f2476d4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0,   1,   2, ..., 497, 498, 499])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-dc997ce1-0147-4432-8144-6a29dd34bdbb' class='xr-section-summary-in' type='checkbox'  checked><label for='section-dc997ce1-0147-4432-8144-6a29dd34bdbb' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>y</span></div><div class='xr-var-dims'>(date, sample)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.1 1.482 2.196 ... 1.375 0.03829</div><input id='attrs-8a5d7c24-6ab6-40fa-920d-5c5f380b3327' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8a5d7c24-6ab6-40fa-920d-5c5f380b3327' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fb7d4a0d-d818-4e66-aa02-33f39541c12c' class='xr-var-data-in' type='checkbox'><label for='data-fb7d4a0d-d818-4e66-aa02-33f39541c12c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.10046376, 1.48223506, 2.1955386 , ..., 0.54750498, 2.51726368,\n        2.28408282],\n       [0.16650521, 3.43133933, 0.26637452, ..., 1.42749722, 0.27062395,\n        0.57967649],\n       [0.56776237, 1.27514195, 0.48324084, ..., 0.92168378, 0.92254179,\n        3.28625954],\n       ...,\n       [0.18217287, 0.7784404 , 0.99589786, ..., 0.3352403 , 1.08227801,\n        3.23752939],\n       [0.46625045, 0.84496526, 0.56362764, ..., 1.80404267, 0.16434128,\n        0.64053605],\n       [0.33083515, 0.41383744, 0.08532088, ..., 0.07563847, 1.3749999 ,\n        0.03828513]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>y_original_scale</span></div><div class='xr-var-dims'>(date, sample)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.095e+03 1.475e+03 ... 38.1</div><input id='attrs-7059af9b-156e-474b-b383-94ecc654c6c2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7059af9b-156e-474b-b383-94ecc654c6c2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fb32c4b5-aef3-4340-832f-1bc0ea51e232' class='xr-var-data-in' type='checkbox'><label for='data-fb32c4b5-aef3-4340-832f-1bc0ea51e232' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1095.19409128, 1475.13724952, 2185.02506694, ...,  544.88320768,\n        2505.20954088, 2273.14528242],\n       [ 165.70788563, 3414.90806101,  265.09895954, ..., 1420.66152142,\n         269.32804098,  576.90065413],\n       [ 565.04359032, 1269.03581642,  480.92680241, ...,  917.27021906,\n         918.12411735, 3270.52299438],\n       ...,\n       [ 181.30051596,  774.71277048,  991.12891293, ...,  333.63497257,\n        1077.09542741, 3222.02619248],\n       [ 464.01776871,  840.919069  ,  560.92865733, ..., 1795.40385374,\n         163.55431512,  637.468789  ],\n       [ 329.2509134 ,  411.85574076,   84.91231072, ...,   75.27626502,\n        1368.41559187,   38.10180035]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-12825f78-0fc8-454d-a478-32df5cd0eefc' class='xr-section-summary-in' type='checkbox'  ><label for='section-12825f78-0fc8-454d-a478-32df5cd0eefc' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>date</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-a0687b94-d334-4eb1-bd33-eab8f71b14bc' class='xr-index-data-in' type='checkbox'/><label for='index-a0687b94-d334-4eb1-bd33-eab8f71b14bc' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2024-09-02&#x27;, &#x27;2024-09-09&#x27;, &#x27;2024-09-16&#x27;, &#x27;2024-09-23&#x27;,\n               &#x27;2024-09-30&#x27;, &#x27;2024-10-07&#x27;, &#x27;2024-10-14&#x27;, &#x27;2024-10-21&#x27;,\n               &#x27;2024-10-28&#x27;, &#x27;2024-11-04&#x27;, &#x27;2024-11-11&#x27;, &#x27;2024-11-18&#x27;,\n               &#x27;2024-11-25&#x27;, &#x27;2024-12-02&#x27;, &#x27;2024-12-09&#x27;, &#x27;2024-12-16&#x27;,\n               &#x27;2024-12-23&#x27;, &#x27;2024-12-30&#x27;, &#x27;2025-01-06&#x27;, &#x27;2025-01-13&#x27;,\n               &#x27;2025-01-20&#x27;, &#x27;2025-01-27&#x27;, &#x27;2025-02-03&#x27;, &#x27;2025-02-10&#x27;,\n               &#x27;2025-02-17&#x27;, &#x27;2025-02-24&#x27;, &#x27;2025-03-03&#x27;, &#x27;2025-03-10&#x27;,\n               &#x27;2025-03-17&#x27;, &#x27;2025-03-24&#x27;, &#x27;2025-03-31&#x27;, &#x27;2025-04-07&#x27;,\n               &#x27;2025-04-14&#x27;, &#x27;2025-04-21&#x27;, &#x27;2025-04-28&#x27;, &#x27;2025-05-05&#x27;,\n               &#x27;2025-05-12&#x27;, &#x27;2025-05-19&#x27;, &#x27;2025-05-26&#x27;, &#x27;2025-06-02&#x27;,\n               &#x27;2025-06-09&#x27;, &#x27;2025-06-16&#x27;, &#x27;2025-06-23&#x27;, &#x27;2025-06-30&#x27;,\n               &#x27;2025-07-07&#x27;, &#x27;2025-07-14&#x27;, &#x27;2025-07-21&#x27;, &#x27;2025-07-28&#x27;,\n               &#x27;2025-08-04&#x27;, &#x27;2025-08-11&#x27;, &#x27;2025-08-18&#x27;, &#x27;2025-08-25&#x27;],\n              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;date&#x27;, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>sample<br>chain<br>draw</div></div><div class='xr-index-preview'>PandasMultiIndex</div><input type='checkbox' disabled/><label></label><input id='index-97a0b7a2-7ce1-4c9c-b6c9-c4377893c78f' class='xr-index-data-in' type='checkbox'/><label for='index-97a0b7a2-7ce1-4c9c-b6c9-c4377893c78f' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(MultiIndex([(0,   0),\n            (0,   1),\n            (0,   2),\n            (0,   3),\n            (0,   4),\n            (0,   5),\n            (0,   6),\n            (0,   7),\n            (0,   8),\n            (0,   9),\n            ...\n            (3, 490),\n            (3, 491),\n            (3, 492),\n            (3, 493),\n            (3, 494),\n            (3, 495),\n            (3, 496),\n            (3, 497),\n            (3, 498),\n            (3, 499)],\n           name=&#x27;sample&#x27;, length=2000))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e201e77a-bf6e-44ef-b500-153257fdb59f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-e201e77a-bf6e-44ef-b500-153257fdb59f' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>created_at :</span></dt><dd>2025-08-23T19:04:45.359585+00:00</dd><dt><span>arviz_version :</span></dt><dd>0.21.0</dd><dt><span>inference_library :</span></dt><dd>pymc</dd><dt><span>inference_library_version :</span></dt><dd>5.25.1</dd></dl></div></li></ul></div></div>\n```\n:::\n:::\n\n\nGreat, no divergences üî•\n\n::: {#9fd7d0c2 .cell execution_count=16}\n``` {.python .cell-code}\nmmm.idata.sample_stats.diverging.sum().item()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n0\n```\n:::\n:::\n\n\nNow we inspect the parameters relevant for optimization.\n\n::: {#1991d852 .cell execution_count=17}\n``` {.python .cell-code}\nmedia_vars = [\n    \"saturation_alpha\",\n    \"saturation_lam\",\n    \"adstock_alpha\",\n]\n\n_ = az.plot_trace(\n    data=mmm.fit_result,\n    var_names=media_vars,\n    compact=True,\n    backend_kwargs={\"figsize\": default_figsize, \"layout\": \"constrained\"},\n)\nplt.gcf().suptitle(\"Model Trace\", fontsize=16, fontweight=\"bold\", y=1.03);\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-18-output-1.png){width=811 height=427}\n:::\n:::\n\n\nAs expected, some parameters are well identified while others remain uncertain.\n\nSampling saturation curves from the posterior helps us visualize parameter uncertainty as bands around each channel‚Äôs response. Wide bands indicate poorly identified marginal returns; allocating in those regions increases outcome variance because small parameter shifts cause large changes in response.\n\n::: {#6889ea8f .cell execution_count=18}\n``` {.python .cell-code}\ncurve = mmm.saturation.sample_curve(\n    mmm.idata.posterior[[\"saturation_alpha\", \"saturation_lam\"]], max_value=3\n)\n\nfig, axes = mmm.plot.saturation_curves(\n    curve,\n    original_scale=True,\n    n_samples=10,\n    hdi_probs=0.85,\n    random_seed=rng,\n    subplot_kwargs={\"figsize\": default_figsize, \"ncols\": 4, \"sharey\": True},\n    rc_params={\n        \"xtick.labelsize\": 10,\n        \"ytick.labelsize\": 10,\n        \"axes.labelsize\": 10,\n        \"axes.titlesize\": 10,\n    },\n\n)\n\nfor ax in axes.ravel():\n    ax.title.set_fontsize(10)\n\nif fig._suptitle is not None:\n    fig._suptitle.set_fontsize(12)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"b1038c311b09450088b9990665f61a51\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-19-output-3.png){width=795 height=390}\n:::\n:::\n\n\nThe picture is clear: channels like X1 and X3 exhibit more variation across spend levels, allowing the model to learn their parameters more precisely. Channels like X2 and X4 have relatively constant spending with less variation, so their parameters are estimated with greater uncertainty.\n\n# üé≤ Understanding uncertainty\n\nIn a Bayesian MMM we explicitly model two forms of uncertainty that compound in forecasts and in budget decisions:\n\n- Aleatoric uncertainty: randomness in outcomes conditional on fixed parameters. In the simulation, this is `epsilon`. Formally, if parameters are $\\theta$, aleatoric uncertainty is the spread of $p(y\\mid x,\\theta)$ once we model the likelihood as $\\mathcal{N}(0, \\sigma^2)$. In our model, the parameter $\\sigma$ explicitly captures aleatoric uncertainty: it quantifies the amount of outcome variability that remains even if all structural parameters $\\theta$ were known exactly. It represents inherent unpredictability due to unobserved micro-variation, demand shocks, or logging noise. Even with infinite data, aleatoric uncertainty remains.\n\n- Epistemic uncertainty: uncertainty about the parameters and latent functions themselves due to limited or weakly informative data. This is the spread of the posterior $p(\\theta\\mid \\text{data})$. It shrinks with more data, better priors, or richer experimental variation. In our model it includes carryover memory (adstock $\\alpha$), saturation curvature and half-saturation (Michaelis‚ÄìMenten $\\alpha,\\lambda$), trend slopes, and seasonal Fourier weights.\n\nWhy this separation matters for planning:\n\n1) Outcome distribution under a plan. For a given allocation plan $b$ over channels and time, the posterior predictive is\n$$\np\\big(Y(b)\\mid \\text{data}\\big) = \\int p\\big(Y(b)\\mid \\theta\\big)\\, p(\\theta\\mid \\text{data})\\, d\\theta,\n$$\nwhich mixes aleatoric variability (the inner term) and epistemic variability (integration over $\\theta$). Our Monte Carlo estimator samples $\\theta^{(s)}$ from the posterior, simulates carryover and saturation under $b$, and draws predictive outcomes.\n\n2) Example: known vs unknown curvature. Suppose a channel‚Äôs saturation is well learned around historical spends but not beyond. Two plans with the same total spend differ in risk:\n\n   - Plan A concentrates around the historical mode (epistemic low), yielding a narrow predictive distribution.\n   - Plan B pushes beyond observed spends (epistemic high), producing a wider distribution and heavier downside tails if the curve flattens earlier than hoped.\n\nDuring optimization, we focus on the second component ‚Äîepistemic uncertainty‚Äî and can choose how much confidence we require around it. Once we choose an allocation, then we incorporate aleatoric uncertainty to quantify the total response distribution, if we want to.\n\n# üß≠ Optimization\n\nBecause the posterior predictive distribution\n$$\np\\big(Y(b)\\mid \\text{data}\\big) = \\int p\\big(Y(b)\\mid \\theta\\big)\\, p(\\theta\\mid \\text{data})\\, d\\theta\n$$\nalready incorporates both aleatoric and epistemic uncertainty, the optimization problem reduces to choosing an allocation $b$ that optimizes a scalar summary of this distribution.\n\nFormally, let $b \\in \\mathbb{R}^C$ denote a feasible allocation (e.g., channel budgets) with constraints\n$$\n\\sum_{c=1}^C b_c = B, \\qquad \\underline{b}_c \\leq b_c \\leq \\overline{b}_c.\n$$\n\nFor each candidate allocation $b$, we obtain Monte Carlo draws\n$$\n\\{Y^{(s)}(b)\\}_{s=1}^S \\sim p(Y \\mid \\mathrm{do}(X=b), \\mathcal{D}),\n$$\n\nfrom the posterior predictive distribution. A statistic\n$$\n\\phi\\!\\left(\\{Y^{(s)}(b)\\}\\right)\n$$\n\nis then computed (for example, the mean, a quantile, a risk-adjusted score, or the mean tightness score).  \n\nBy consequence, the optimization problem solved by SLSQP is simply\n$$\n\\min_{b \\in \\mathcal{B}} J(b), \\qquad J(b) = f\\!\\left(\\phi(\\{Y^{(s)}(b)\\})\\right),\n$$\n\nwhere $f$ is defined so the solver minimizes the chosen statistic from the posterior predictive distribution.  \n\nThis formulation is flexible: by changing $\\phi$, we can target risk-neutral or risk-sensitive criteria, while always grounding the decision in the posterior predictive distribution.\n\n::: {.callout-note}\n## üí° Assumption notes\nWhy do we say do=$(X=b)$?\n\n- **Structural invariance**: The response functions (trend, seasonality, adstock, saturation, link) are invariant under interventions $b$ over the optimization horizon.\n- **No unmeasured confounding**: Conditional on included covariates and time controls, there are no unmeasured (especially time-varying) confounders affecting both spend and outcome; the backdoor criterion holds.\n\nWe use $p\\big(Y \\mid \\mathrm{do}(X=b), \\mathcal{D}\\big)$ as shorthand for the posterior predictive under these assumptions. When allocations move far outside support, results become extrapolative and should be treated as sensitivity analysis rather than identified effects.\n:::\n\n## üõ†Ô∏è Define the optimizer\n\nInitializing the optimizer is straightforward: pass the model and the date range.\n\n::: {#58168569 .cell execution_count=19}\n``` {.python .cell-code}\noptimizable_model = MultiDimensionalBudgetOptimizerWrapper(\n    model=mmm, \n    start_date=df_test.date_week.min().strftime(\"%Y-%m-%d\"), \n    end_date=df_test.date_week.max().strftime(\"%Y-%m-%d\")\n)\nprint(f\"Start date: {optimizable_model.start_date}\")\nprint(f\"End date: {optimizable_model.end_date}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart date: 2025-09-01\nEnd date: 2025-09-01\n```\n:::\n:::\n\n\nWe'll use the test set to define the budget and optimization period so we can compare the resulting allocation to our current plan.\n\n::: {#c265e5a0 .cell execution_count=20}\n``` {.python .cell-code}\nchannels = [\"x1_original_scale\", \"x2_original_scale\", \"x3_original_scale\", \"x4_original_scale\"]\nnum_periods = optimizable_model.num_periods\ntime_unit_budget = df_test[channels].sum(axis=1).mean()\nprint(f\"Total budget to allocate: {num_periods * time_unit_budget:,.0f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal budget to allocate: 59\n```\n:::\n:::\n\n\nGiven the budget and channels, we can estimate the response for our initial plan.\n\n::: {#c0a88855 .cell execution_count=21}\n``` {.python .cell-code}\ninitial_budget = df_test[channels].sum(axis=0).to_xarray().rename({\"index\":\"channel\"})\ninitial_posterior_response = optimizable_model.sample_response_distribution(\n    allocation_strategy=initial_budget,\n    include_carryover=True,\n    include_last_observations=False,\n    additional_var_names=[\"y_original_scale\"]\n)\n\nfig, ax = optimizable_model.plot.budget_allocation(\n    samples=initial_posterior_response,\n    figsize=default_figsize,\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-22-output-1.png){width=811 height=411}\n:::\n:::\n\n\nThe bar chart shows allocation and response per channel. To see totals, we can sum and create a simple scatter plot with a label for the ROAS.\n\n::: {#dd82ffb7 .cell execution_count=22}\n``` {.python .cell-code}\n# Create scatterplot with spend and mean response\nspend = initial_posterior_response.allocation.sum().values\nmean_response = initial_posterior_response.total_media_contribution_original_scale.mean(dim='sample').values\n\ninitial_roas = mean_response / spend\n\nplt.scatter(spend, mean_response, alpha=0.7, s=100, label=f\"ROAS: {initial_roas:.2f}\")\nplt.xlabel('Spend')\nplt.ylabel('Mean Response')\nplt.title('Spend vs Mean Response')\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize='small', loc='upper left')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-23-output-1.png){width=811 height=411}\n:::\n:::\n\n\nWe got a ROAS of $3.9$ for the initial plan, which is below our target ROAS (let's say $8$). Now we run a vanilla optimization to maximize mean response: can we reallocate to achieve a higher response given the same budget?\n\n::: {#afac2f29 .cell execution_count=23}\n``` {.python .cell-code}\nallocation_strategy, optimization_result = optimizable_model.optimize_budget(\n    budget=time_unit_budget,\n)\n\nnaive_posterior_response = optimizable_model.sample_response_distribution(\n    allocation_strategy=allocation_strategy,\n    include_carryover=True,\n    include_last_observations=False,\n    additional_var_names=[\"y_original_scale\"]\n)\n\nprint(\"Budget allocation by channel:\")\nfor channel in channels:\n    print(\n        f\"  {channel}: {naive_posterior_response.allocation.sel(channel=channel).astype(int).sum():,}\"\n    )\nprint(\n    f\"Total Allocated Budget: {np.sum(naive_posterior_response.allocation.to_numpy()):,.0f}\"\n)\n\nfig, ax = optimizable_model.plot.budget_allocation(\n    samples=naive_posterior_response,\n    figsize=default_figsize,\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBudget allocation by channel:\n  x1_original_scale: 0\n  x2_original_scale: 0\n  x3_original_scale: 16\n  x4_original_scale: 42\nTotal Allocated Budget: 59\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-24-output-2.png){width=811 height=411}\n:::\n:::\n\n\nYes, we can allocate to achieve a higher response. Let's compare the optimized response against the baseline plan.\n\n::: {#4e1bb805 .cell execution_count=24}\n``` {.python .cell-code}\n# Create scatterplot with spend and mean response\nmean_response_v2 = naive_posterior_response.total_media_contribution_original_scale.mean(dim='sample').values\nroas_v2 = mean_response_v2 / spend\n\n# Calculate the delta in response\nresponse_delta = mean_response_v2.sum() - mean_response.sum()\n\nplt.scatter(spend, mean_response_v2, alpha=0.7, s=100, color=\"blue\", label=f\"Optimized allocation (+{response_delta:.1f} response, ROAS: {roas_v2:.2f})\")\nplt.scatter(spend, mean_response, alpha=0.7, s=100, color=\"red\", label=\"Guessed allocation\")\n\nplt.xlabel('Spend')\nplt.ylabel('Mean Response')\nplt.title('Spend vs Mean Response')\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize='small', loc='upper left')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-25-output-1.png){width=811 height=411}\n:::\n:::\n\n\nThe optimized allocation is ~$500$ units higher than the guessed allocation, and the new estimated ROAS is $13$ which it's over our expectations. As consequence, we assume we'll get an estimate Y revenue in the next N periods and planning against this incoming cashflow we'll get back.\n\nThe plotwist? We got a lower response, which mean a lower ROAS and we got in serious financial problems because we don't have enough cash to payback providers or services.\n\nWhy this happen? Maximizing the mean response is risk-neutral. It often reallocates budget toward regions with potential high returns even if they are weakly identified, increasing dispersion of outcomes. This is rational when stakeholders are indifferent to risk. However, that's not the case for every company. Sometimes our stakeholders need to know how certain we are about expected outcomes.\n\nBy inspecting posterior predictive samples under each allocation, we can quantify uncertainty and answer this question, based on the model current understanding.\n\nLet's plot the response distributions for both baseline and optimized allocations.\n\n::: {#4503a2f7 .cell execution_count=25}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\n\n# Get the values\noptimized_values = naive_posterior_response.total_media_contribution_original_scale.values\nguessed_values = initial_posterior_response.total_media_contribution_original_scale.values\n\n# Plot distributions\naz.plot_dist(\n    optimized_values,\n    color=\"blue\",\n    label=\"Optimized allocation\",\n    ax=ax,\n)\naz.plot_dist(\n    guessed_values,\n    color=\"red\",\n    label=\"Guessed allocation\",\n    ax=ax,\n)\n\n# Calculate means\noptimized_mean = optimized_values.mean()\nguessed_mean = guessed_values.mean()\n\n# Add vertical lines for means\nax.axvline(optimized_mean, color=\"blue\", linestyle=\"--\", alpha=0.8)\nax.axvline(guessed_mean, color=\"red\", linestyle=\"--\", alpha=0.8)\n\n# Add text boxes with mean values\nax.text(optimized_mean + 10, ax.get_ylim()[1] * 0.8, \n        f'Optimized Mean:\\n{optimized_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n        ha='left', va='center')\n\nax.text(guessed_mean - 10, ax.get_ylim()[1] * 0.6, \n        f'Guessed Mean:\\n{guessed_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7),\n        ha='right', va='center')\n\nplt.title(\"Response Distribution\")\nplt.xlabel(\"Total Media Contribution\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-26-output-1.png){width=810 height=411}\n:::\n:::\n\n\nAs expected, the means differ (we optimized to increase it), and so does the certainty around the mean. Like an excersise, lets observe how probable is to get a response higher and lower than the mean.\n\n::: {#44837e8f .cell execution_count=26}\n``` {.python .cell-code}\naz.plot_posterior(\n    optimized_values,\n    figsize=default_figsize,\n    ref_val=optimized_mean,\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-27-output-1.png){width=811 height=411}\n:::\n:::\n\n\nThis makes everything clear now, the chances of getting some higher or equal than the mean where 43% but the chances of getting some lower than the mean where 56%. It's no surprise that we got a lower response and a lower ROAS.\n\n::: {.callout-tip icon=false}\n## üí° First Takeaway\nComparing full distributions makes risk transparent: width quantifies forecast reliability, skewness reveals asymmetry of upside vs downside, and overlaps show practical indistinguishability. \n:::\n\nWhere this risk is coming from? The new allocation is riskier, but why? Let's look at each spend level relative to its saturation curve.\n\n::: {#c81b247e .cell execution_count=27}\n``` {.python .cell-code}\ncurve = mmm.saturation.sample_curve(\n    mmm.idata.posterior[[\"saturation_alpha\", \"saturation_lam\"]], max_value=10\n)\n\nfig, axes = mmm.plot.saturation_curves(\n    curve,\n    original_scale=True,\n    n_samples=10,\n    hdi_probs=0.85,\n    random_seed=rng,\n    subplot_kwargs={\"figsize\": default_figsize, \"ncols\": 4, \"sharey\": True},\n    rc_params={\n        \"xtick.labelsize\": 10,\n        \"ytick.labelsize\": 10,\n        \"axes.labelsize\": 10,\n        \"axes.titlesize\": 10,\n    },\n\n)\n\n# Add vertical lines for optimal allocation on each subplot\nallocation_values = naive_posterior_response.allocation.values\nchannel_names = naive_posterior_response.allocation.channel.values\n\nfor i, (ax, allocation_value) in enumerate(zip(axes.ravel(), allocation_values)):\n    ax.axvline(allocation_value, color=\"red\", linestyle=\"--\", alpha=0.8, linewidth=2, label=\"Optimal allocation\")\n    ax.title.set_fontsize(10)\n\nif fig._suptitle is not None:\n    fig._suptitle.set_fontsize(12)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"cfbd25131892493b82d4ca03289ffcf5\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-28-output-3.png){width=796 height=390}\n:::\n:::\n\n\nVertical lines are located at the spend allocation given for each channel. For channels as x4, the model has few observations at those spend levels, so posterior bands are wide and the induced response distribution is diffuse. Risk-aware optimization tends to pull spend toward well-identified regions (often near inflection), trading a small mean decrease for a large reduction in variance.\n\nCould we understand this in advance? and if so, would we prefer a different type of allocation? Which get us closer to our objective in a safer way? -A narrower distribution with a slightly lower mean can be preferable when shortfall risk is costly-.\n\nThe short answer is **definetly**. Let's create now a new optimization process that will be risk-aware. \n\n# ‚öñÔ∏è Risk metrics consistent with PyMC-Marketing\n\nBelow are the definitions of two risk-aware metrics as implemented in the PyMC-Marketing library.\n\n---\n\n## üå™Ô∏è Tail Distance\n\nFor a confidence level $\\gamma \\in (0,1)$,\n\n$$\n\\operatorname{TailDistance}_\\gamma(Y) \\;=\\; \n\\big|Q_{1-\\gamma}(Y) - \\mu\\big| \\;+\\; \\big|\\mu - Q_{\\gamma}(Y)\\big|,\n$$\n\nwhere \n- $\\mu = \\mathbb{E}[Y]$ is the mean (estimated by the sample mean),  \n- $Q_q(Y)$ is the $q$-th quantile of the distribution of $Y$.\n\nThis metric measures the **spread of the distribution's tails around the mean**.  \nLarger values indicate wider tails and thus higher uncertainty.\n\n---\n\n## üéØ Mean Tightness Score (MTS)\n\nThe Mean Tightness Score combines the mean with a penalty for tail spread:\n\n$$\n\\operatorname{MTS}(Y; \\alpha, \\gamma) \\;=\\; \n\\mu \\;-\\; \\alpha \\cdot \\operatorname{TailDistance}_\\gamma(Y),\n$$\n\nwhere \n- $\\mu = \\mathbb{E}[Y]$ is the mean,  \n- $\\gamma$ is the confidence level used for the tail distance,  \n- $\\alpha > 0$ is a penalty weight that controls the trade-off between higher mean and tighter distribution.\n\nInterpretation:  \n- **Higher is better:** Allocations with higher means and smaller dispersion score better.  This provides a balance between risk-neutral (maximize mean) and risk-averse (penalize uncertainty) optimization.\n\nLet's optimize with the Mean Tightness Score and see the resulting allocation.\n\n::: {#4236255e .cell execution_count=28}\n``` {.python .cell-code}\nmts_budget_allocation, mts_optimizer_result, callback_results = (\n    optimizable_model.optimize_budget(\n        budget=time_unit_budget,\n        utility_function=ut.mean_tightness_score(alpha=0.15),\n        callback=True,\n        minimize_kwargs={\"options\": {\"maxiter\": 2_000, \"ftol\": 1e-16}},\n    )\n)\n\nmts_posterior_response = optimizable_model.sample_response_distribution(\n    allocation_strategy=mts_budget_allocation,\n    include_carryover=True,\n    include_last_observations=False,\n    additional_var_names=[\"y_original_scale\"]\n)\n\n# Print budget allocation by channel\nprint(\"Budget allocation by channel:\")\nfor channel in channels:\n    print(\n        f\"  {channel}: {mts_posterior_response.allocation.sel(channel=channel).astype(int).sum():,}\"\n    )\nprint(\n    f\"Total Allocated Budget: {np.sum(mts_posterior_response.allocation.to_numpy()):,.0f}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBudget allocation by channel:\n  x1_original_scale: 16\n  x2_original_scale: 38\n  x3_original_scale: 2\n  x4_original_scale: 1\nTotal Allocated Budget: 59\n```\n:::\n:::\n\n\nGreat, it looks like the allocation shifts toward better-identified regions. Let's plot the saturation curves to see where the allocation lands.\n\n::: {#30fd0fb8 .cell execution_count=29}\n``` {.python .cell-code}\ncurve = mmm.saturation.sample_curve(\n    mmm.idata.posterior[[\"saturation_alpha\", \"saturation_lam\"]], max_value=4\n)\n\nfig, axes = mmm.plot.saturation_curves(\n    curve,\n    original_scale=True,\n    n_samples=10,\n    hdi_probs=0.85,\n    random_seed=rng,\n    subplot_kwargs={\"figsize\": default_figsize, \"ncols\": 4, \"sharey\": True},\n    rc_params={\n        \"xtick.labelsize\": 10,\n        \"ytick.labelsize\": 10,\n        \"axes.labelsize\": 10,\n        \"axes.titlesize\": 10,\n    },\n\n)\n\n# Add vertical lines for optimal allocation on each subplot\nallocation_values = mts_posterior_response.allocation.values\n\nfor i, (ax, allocation_value) in enumerate(zip(axes.ravel(), allocation_values)):\n    ax.axvline(allocation_value, color=\"red\", linestyle=\"--\", alpha=0.8, linewidth=2, label=\"Optimal allocation\")\n    ax.title.set_fontsize(10)\n\nif fig._suptitle is not None:\n    fig._suptitle.set_fontsize(12)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"7106674b48074ab68abc743daaaedb91\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-30-output-3.png){width=798 height=390}\n:::\n:::\n\n\nAs expected, recommendations for every channel lie in well-known regions.\n\nThe consequence: the posterior distribution narrows because budget concentrates in well-learned, less-nonlinear regions.\n\nLet's plot posterior distributions for this lower-risk allocation.\n\n::: {#6f41cb26 .cell execution_count=30}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\n\n# Get the values\noptimized_risk_values = mts_posterior_response.total_media_contribution_original_scale.values\n\n# Plot distributions\naz.plot_dist(\n    optimized_values,\n    color=\"blue\",\n    label=\"Optimized allocation\",\n    ax=ax,\n)\naz.plot_dist(\n    guessed_values,\n    color=\"red\",\n    label=\"Guessed allocation\",\n    ax=ax,\n)\naz.plot_dist(\n    optimized_risk_values,\n    color=\"green\",\n    label=\"Risk-adjusted allocation\",\n    ax=ax,\n)\n\n# Calculate means\nrisk_adjusted_mean = optimized_risk_values.mean()\n\n# Add vertical lines for means\nax.axvline(optimized_mean, color=\"blue\", linestyle=\"--\", alpha=0.8)\nax.axvline(guessed_mean, color=\"red\", linestyle=\"--\", alpha=0.8)\nax.axvline(risk_adjusted_mean, color=\"green\", linestyle=\"--\", alpha=0.8)\n\n# Add text boxes with mean values\nax.text(optimized_mean + 10, ax.get_ylim()[1] * 0.8, \n        f'Optimized Mean:\\n{optimized_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n        ha='left', va='center')\n\nax.text(guessed_mean - 10, ax.get_ylim()[1] * 0.6, \n        f'Guessed Mean:\\n{guessed_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7),\n        ha='right', va='center')\n\nax.text(risk_adjusted_mean - 10, ax.get_ylim()[1] * 0.4, \n        f'Risk-adjusted Mean:\\n{risk_adjusted_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7),\n        ha='right', va='center')\n\nplt.title(\"Response Distribution\")\nplt.xlabel(\"Total Media Contribution\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-31-output-1.png){width=811 height=411}\n:::\n:::\n\n\nThis makes it clear: we gained much more certainty‚Äîa risk-averse (lower-variance) response distribution. You may be thinking that playing in known regions tends to reduce the mean. Do you want to know why?\n\nPosterior response curves tend to be more certain at the origin because two sources of uncertainty are minimized there: structurally, we know that zero spend produces zero incremental effect, and empirically, the lowest spend region is often well supported in historical data. As spend increases, especially beyond historically observed levels, epistemic uncertainty about the saturation and curvature parameters dominates, widening the credible intervals.\n\nDoes that mean we are doomed to lower values if we want certainty? Not at all, we can change the utility to prefer riskier options üî•.\n\nLet's run a more risk-seeking allocation üëÄ\n\n::: {#f9bb353f .cell execution_count=31}\n``` {.python .cell-code}\ninverse_mts_budget_allocation, inverse_mts_optimizer_result, callback_results = (\n    optimizable_model.optimize_budget(\n        budget=time_unit_budget,\n        utility_function=ut.mean_tightness_score(alpha=0.95),\n        callback=True,\n        minimize_kwargs={\"options\": {\"maxiter\": 2_000, \"ftol\": 1e-16}},\n    )\n)\n\ninverse_mts_posterior_response = optimizable_model.sample_response_distribution(\n    allocation_strategy=inverse_mts_budget_allocation,\n    include_carryover=True,\n    include_last_observations=False,\n    additional_var_names=[\"y_original_scale\"]\n)\n\n# Print budget allocation by channel\nprint(\"Budget allocation by channel:\")\nfor channel in channels:\n    print(\n        f\"  {channel}: {inverse_mts_posterior_response.allocation.sel(channel=channel).astype(int).sum():,}\"\n    )\nprint(\n    f\"Total Allocated Budget: {np.sum(inverse_mts_posterior_response.allocation.to_numpy()):,.0f}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBudget allocation by channel:\n  x1_original_scale: 38\n  x2_original_scale: 0\n  x3_original_scale: 8\n  x4_original_scale: 12\nTotal Allocated Budget: 59\n```\n:::\n:::\n\n\nFlipping the tightness preference (alpha parameter) induces risk-seeking behavior, moving allocations toward higher-variance, high-upside regions.\n\nNow we choose an allocation that is less certain but with higher potential upside than the baseline. Let's plot the response distributions. \n\n::: {.callout-tip icon=false}\n## üí° Second Takeaway\nDiscover your risk preferences and adjust your objective function to reflect them. You don't need to commit to a single function or approach, you can build a custom one which tailor your needs.\n:::\n\n::: {#fed9a249 .cell execution_count=32}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\n\n# Get the values\noptimized_inverse_risk_values = inverse_mts_posterior_response.total_media_contribution_original_scale.values\n\n# Plot distributions\naz.plot_dist(\n    optimized_values,\n    color=\"blue\",\n    label=\"Optimized allocation\",\n    ax=ax,\n)\naz.plot_dist(\n    guessed_values,\n    color=\"red\",\n    label=\"Guessed allocation\",\n    ax=ax,\n)\naz.plot_dist(\n    optimized_risk_values,\n    color=\"green\",\n    label=\"Risk-adjusted allocation\",\n    ax=ax,\n)\n\naz.plot_dist(\n    optimized_inverse_risk_values,\n    color=\"orange\",\n    label=\"Inverse Risk-adjusted allocation\",\n    ax=ax,\n)\n\n# Calculate means\ninverse_risk_adjusted_mean = optimized_inverse_risk_values.mean()\n\n# Add vertical lines for means\nax.axvline(optimized_mean, color=\"blue\", linestyle=\"--\", alpha=0.8)\nax.axvline(guessed_mean, color=\"red\", linestyle=\"--\", alpha=0.8)\nax.axvline(risk_adjusted_mean, color=\"green\", linestyle=\"--\", alpha=0.8)\nax.axvline(inverse_risk_adjusted_mean, color=\"orange\", linestyle=\"--\", alpha=0.8)\n\n# Add text boxes with mean values\nax.text(optimized_mean + 10, ax.get_ylim()[1] * 0.8, \n        f'Optimized Mean:\\n{optimized_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n        ha='left', va='center')\n\nax.text(guessed_mean - 10, ax.get_ylim()[1] * 0.6, \n        f'Guessed Mean:\\n{guessed_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7),\n        ha='right', va='center')\n\nax.text(risk_adjusted_mean - 10, ax.get_ylim()[1] * 0.4, \n        f'Risk-adjusted Mean:\\n{risk_adjusted_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7),\n        ha='right', va='center')\n\nax.text(inverse_risk_adjusted_mean - 10, ax.get_ylim()[1] * 0.2, \n        f'Inverse Risk-adjusted Mean:\\n{inverse_risk_adjusted_mean:.1f}', \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"orange\", alpha=0.7),\n        ha='right', va='center')\n\nplt.title(\"Response Distribution\")\nplt.xlabel(\"Total Media Contribution\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-33-output-1.png){width=811 height=411}\n:::\n:::\n\n\nGreat, the new allocation is riskier, and the mean is higher (still less uncertant than the risk-neutral allocation). We can go beyond visuals and quantify this.\n\nBecause all are posterior distributions, we can check the density that has each response distribution at their respective mean. We'll be using kernel density estimation (KDE). This value, denoted $\\hat{f}(\\mu)$, represents the estimated height of the probability density function at the mean. Importantly, this is not itself a probability but a density, with units of ‚Äú1 over the units of the variable.‚Äù Higher values of $\\hat{f}(\\mu)$ indicate that the distribution is sharply peaked around the mean, reflecting greater certainty that posterior draws will lie close to the central value. Conversely, lower values correspond to flatter, more diffuse posteriors, indicating higher uncertainty.\n\nLet's check the density at the mean for each allocation.\n\n::: {#6e99d8d8 .cell execution_count=33}\n``` {.python .cell-code}\nfrom scipy.stats import gaussian_kde\n\ndef kde_density_at_point(x, x0):\n    \"\"\"Gaussian KDE density estimate at x0 using Scott's rule bandwidth.\"\"\"\n    kde = gaussian_kde(x)  # Scott's rule by default\n    return float(kde.evaluate([x0])[0])\n\noptimized_density = kde_density_at_point(optimized_values, optimized_mean)\nguessed_density = kde_density_at_point(guessed_values, guessed_mean)\nrisk_adjusted_density = kde_density_at_point(optimized_risk_values, risk_adjusted_mean)\ninverse_risk_adjusted_density = kde_density_at_point(optimized_inverse_risk_values, inverse_risk_adjusted_mean)\n\nprint(f\"Optimized allocation response density at mean: {optimized_density:.3f}\")\nprint(f\"Guessed allocation response density at mean: {guessed_density:.3f}\")\nprint(f\"Risk-adjusted allocation response density at mean: {risk_adjusted_density:.3f}\")\nprint(f\"Inverse Risk-adjusted allocation response density at mean: {inverse_risk_adjusted_density:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimized allocation response density at mean: 0.001\nGuessed allocation response density at mean: 0.005\nRisk-adjusted allocation response density at mean: 0.013\nInverse Risk-adjusted allocation response density at mean: 0.003\n```\n:::\n:::\n\n\nThe density estimations tell the same story as the plots. How can we use this to take actions? For example, suppose we want to hit a target ROAS of $9.5$, then we can check the density of the ROAS distribution at $9.5$ for each response distribution given their respective allocation strategy.\n\n::: {#776c3871 .cell execution_count=34}\n``` {.python .cell-code}\noptimized_roas = optimized_values / (time_unit_budget*num_periods)\nguessed_roas = guessed_values / (time_unit_budget*num_periods)\nrisk_adjusted_roas = optimized_risk_values / (time_unit_budget*num_periods)\ninverse_risk_adjusted_roas = optimized_inverse_risk_values / (time_unit_budget*num_periods)\n\n# Calculate kde density at 9.5\n_target_roas = 9.5\noptimized_kde_density = kde_density_at_point(optimized_roas, _target_roas)\nguessed_kde_density = kde_density_at_point(guessed_roas, _target_roas)\nrisk_adjusted_kde_density = kde_density_at_point(risk_adjusted_roas, _target_roas)\ninverse_risk_adjusted_kde_density = kde_density_at_point(inverse_risk_adjusted_roas, _target_roas)\n\n#plot the ROAS distributions\nfig, ax = plt.subplots()\n\n# Plot distributions\naz.plot_dist(optimized_roas, color=\"blue\", label=f\"Optimized allocation: {optimized_kde_density:.3f}\", ax=ax)\naz.plot_dist(guessed_roas, color=\"red\", label=f\"Guessed allocation: {guessed_kde_density:.3f}\", ax=ax)\naz.plot_dist(risk_adjusted_roas, color=\"green\", label=f\"Risk-adjusted allocation: {risk_adjusted_kde_density:.3f}\", ax=ax)\naz.plot_dist(inverse_risk_adjusted_roas, color=\"orange\", label=f\"Inverse Risk-adjusted allocation: {inverse_risk_adjusted_kde_density:.3f}\", ax=ax)\n\n# Add vertical lines for means\nax.axvline(_target_roas, color=\"black\", linestyle=\"--\", alpha=0.8, label=\"Target ROAS\")\n\nplt.tight_layout()\nplt.title(\"ROAS Distribution\")\nplt.xlabel(\"ROAS\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-35-output-1.png){width=790 height=426}\n:::\n:::\n\n\nIf we want to hit a target ROAS of $9.5$, the risk-neutral optimized allocation is the most certain, followed by the inverse risk-adjusted allocation.\n\nIf instead our target ROAS is $7$, the inverse risk-adjusted allocation concentrates more density around that value, and the risk-neutral optimized allocation has less density around it.\n\n::: {#63bb9459 .cell execution_count=35}\n``` {.python .cell-code}\n# Calculate kde density at 7\n_roas_target = 7\noptimized_kde_density = kde_density_at_point(optimized_roas, _roas_target)\nguessed_kde_density = kde_density_at_point(guessed_roas, _roas_target)\nrisk_adjusted_kde_density = kde_density_at_point(risk_adjusted_roas, _roas_target)\ninverse_risk_adjusted_kde_density = kde_density_at_point(inverse_risk_adjusted_roas, _roas_target)\n\n#plot the ROAS distributions\nfig, ax = plt.subplots()\n\n# Plot distributions\naz.plot_dist(optimized_roas, color=\"blue\", label=f\"Optimized allocation: {optimized_kde_density:.3f}\", ax=ax)\naz.plot_dist(guessed_roas, color=\"red\", label=f\"Guessed allocation: {guessed_kde_density:.3f}\", ax=ax)\naz.plot_dist(risk_adjusted_roas, color=\"green\", label=f\"Risk-adjusted allocation: {risk_adjusted_kde_density:.3f}\", ax=ax)\naz.plot_dist(inverse_risk_adjusted_roas, color=\"orange\", label=f\"Inverse Risk-adjusted allocation: {inverse_risk_adjusted_kde_density:.3f}\", ax=ax)\n\n# Add vertical lines for means\nax.axvline(_roas_target, color=\"black\", linestyle=\"--\", alpha=0.8, label=\"Target ROAS\")\n\nplt.tight_layout()\nplt.title(\"ROAS Distribution\")\nplt.xlabel(\"ROAS\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-36-output-1.png){width=790 height=426}\n:::\n:::\n\n\nUnder this paradigm, you can define a target estimate and select an allocation that maximizes the probability of hitting it. One way is to create a function that reduces variance with respect to the target, favoring narrower distributions with density near the target.\n\nLet's make this custom utility function, and see how it performs.\n\n::: {#99bf05c3 .cell execution_count=36}\n``` {.python .cell-code}\nimport pytensor.tensor as pt\nimport pymc_marketing.mmm.utility as ut\n\ndef target_hit_probability(target, num_periods):\n    \"\"\"\n    Target hit probability utility function.\n    \n    Minimizing the mean squared error between predicted ROAS and the target\n    Adding a variance penalty to encourage tighter distributions.\n    \n    Parameters\n    ----------\n    target : float\n        The target ROAS value to optimize towards\n    num_periods : int\n        Number of time periods for the budget allocation\n        \n    Returns\n    -------\n    callable\n        A utility function that can be used with the budget optimizer.\n        Returns negative objective (since optimizer minimizes).\n    \"\"\"\n    def _function(samples, budgets):\n        roas_samples = samples / (pt.sum(budgets) * num_periods)\n        \n        # Use mean squared error from target, which provides smoother gradients\n        mse_from_target = pt.mean((roas_samples - target) ** 2)\n        \n        # Add penalty for variance to encourage tighter distributions around target\n        variance_penalty = pt.var(roas_samples)\n        \n        # Combine MSE and variance penalty with weighting\n        # Higher variance penalty encourages narrower distributions\n        total_objective = mse_from_target + 0.1 * variance_penalty\n        \n        return -total_objective\n    return _function\n\n_roas_target = 8\ncustom_utility_budget_allocation, custom_utility_optimizer_result, callback_results = (\n    optimizable_model.optimize_budget(\n        budget=time_unit_budget,\n        utility_function=target_hit_probability(_roas_target, num_periods),\n        callback=True,\n        minimize_kwargs={\"options\": {\"maxiter\": 2_000}},\n    )\n)\n\ncustom_utility_posterior_response = optimizable_model.sample_response_distribution(\n    allocation_strategy=custom_utility_budget_allocation,\n    include_carryover=True,\n    include_last_observations=False,\n    additional_var_names=[\"y_original_scale\"]\n)\n\n# Print budget allocation by channel\nprint(\"Budget allocation by channel:\")\nfor channel in channels:\n    print(\n        f\"  {channel}: {custom_utility_posterior_response.allocation.sel(channel=channel).astype(int).sum():,}\"\n    )\nprint(\n    f\"Total Allocated Budget: {np.sum(custom_utility_posterior_response.allocation.to_numpy()):,.0f}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBudget allocation by channel:\n  x1_original_scale: 33\n  x2_original_scale: 0\n  x3_original_scale: 17\n  x4_original_scale: 8\nTotal Allocated Budget: 59\n```\n:::\n:::\n\n\nThe allocation is similar to those observed before. Let's plot the ROAS distributions.\n\n::: {#dfa966d2 .cell execution_count=37}\n``` {.python .cell-code}\ncustom_utility_values = custom_utility_posterior_response.total_media_contribution_original_scale.values\ncustom_utility_roas = custom_utility_values / (time_unit_budget*num_periods)\noptimized_kde_density = kde_density_at_point(optimized_roas, _roas_target)\nguessed_kde_density = kde_density_at_point(guessed_roas, _roas_target)\nrisk_adjusted_kde_density = kde_density_at_point(risk_adjusted_roas, _roas_target)\ninverse_risk_adjusted_kde_density = kde_density_at_point(inverse_risk_adjusted_roas, _roas_target)\ncustom_utility_kde_density = kde_density_at_point(custom_utility_roas, _roas_target)\n\n#plot the ROAS distributions\nfig, ax = plt.subplots()\n\n# Plot distributions\naz.plot_dist(optimized_roas, color=\"blue\", label=f\"Optimized allocation: {optimized_kde_density:.3f}\", ax=ax)\naz.plot_dist(guessed_roas, color=\"red\", label=f\"Guessed allocation: {guessed_kde_density:.3f}\", ax=ax)\naz.plot_dist(risk_adjusted_roas, color=\"green\", label=f\"Risk-adjusted allocation: {risk_adjusted_kde_density:.3f}\", ax=ax)\naz.plot_dist(inverse_risk_adjusted_roas, color=\"orange\", label=f\"Inverse Risk-adjusted allocation: {inverse_risk_adjusted_kde_density:.3f}\", ax=ax)\naz.plot_dist(custom_utility_roas, color=\"purple\", label=f\"Custom utility allocation: {custom_utility_kde_density:.3f}\", ax=ax)\n\n# Add vertical lines for means\nax.axvline(_roas_target, color=\"black\", linestyle=\"--\", alpha=0.8, label=\"Target ROAS\")\n\nplt.tight_layout()\nplt.title(\"ROAS Distribution\")\nplt.xlabel(\"ROAS\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-38-output-1.png){width=790 height=426}\n:::\n:::\n\n\nGreat üôåüèª The initial optimized allocation which was risk neutral, had initially the higher density around the target ROAS, but the density around it was not high enough, the new allocation bring a more certain answer around the target, because the objective function was built for it.\n\n::: {.callout-tip icon=false}\n## üí° Key Insight\nHere we have a custom utility function that allows us to optimize for a target ROAS. Nevertheless, you can build other utilities and use them as objectives. You can also introduce risk-aware constraints‚Äîwithout on top of your business constraints.\n:::\n\nLet's observe our final posterior around the target ROAS.\n\n::: {#fedaa8aa .cell execution_count=38}\n``` {.python .cell-code}\naz.plot_posterior(\n    custom_utility_roas, \n    ref_val=_roas_target\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-39-output-1.png){width=811 height=411}\n:::\n:::\n\n\nWe could report: the probability of achieving ROAS ‚â• 10 with this allocation is 31%, and ROAS < 10 is 69%. If we need more certainty, we can make the optimization more risk-averse.\n\nNow, if you want to think really bayesian, then you can define a region of practical equivalence, and check the probability of the ROAS being in that region. For example, you can ask yourself: Would I do something different if ROAS is 7, 8 or 9? If the answer it's no, then you find your ROPE. \n\nLet's say we want to know the probability of the ROAS being between $7$ and $10$.\n\n::: {#2305bba9 .cell execution_count=39}\n``` {.python .cell-code}\n# Calculate probability of ROAS being between 7 and 9\nprob_7_to_9 = np.mean((custom_utility_roas >= 7) & (custom_utility_roas <= 9))\n\n# Plot posterior with reference values and region\nfig, ax = plt.subplots()\naz.plot_posterior(\n    custom_utility_roas, \n    ref_val=_roas_target,\n    ax=ax\n)\n\n# Add vertical lines for the region of interest\nax.axvline(7, color=\"black\", linestyle=\"--\", alpha=0.7, label=\"ROAS = 7\")\nax.axvline(9, color=\"black\", linestyle=\"--\", alpha=0.7, label=\"ROAS = 9\")\n\n# Add text box with probability\nax.text(0.02, 0.98, \n        f'P(7 ‚â§ ROAS ‚â§ 9) = {prob_7_to_9:.2%}', \n        transform=ax.transAxes,\n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8),\n        ha='left', va='top', fontsize=12)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_models_and_risk_optimization_files/figure-html/cell-40-output-1.png){width=811 height=411}\n:::\n:::\n\n\n::: {.callout-tip icon=false}\n## üí° Key Insight\nYou can **define a region of practical equivalence (ROPE)**, in order to be more precise with your decision making. This is quite natural way to think about a problem, and lightens the burden of the decision maker to commit to a single number. At the end of the day, we don't need to be 99.999% precise around every single answer, or number, we can be 95% or 90% precise and sometimes that's enough. *Identify if thats your case, and think accordingly*.\n:::\n\n# ‚úÖ Takeaways on uncertainty\n- **Treat uncertainty as first-class**: Optimize over the full posterior predictive, not point estimates. Compare plans by their distributions, not just expected means.\n- **Separate uncertainty types**: Aleatoric (irreducible noise) vs epistemic (learnable model/parameter uncertainty). Planning choices mostly shift epistemic risk; always communicate both.\n- **Find your risk appetite**: Ask stakeholders how certain we must be about reported results. What changes if they are a bit higher or lower?\n- **Choose a utility aligned to risk appetite**: Working with the mean is risk-neutral; quantiles, TailDistance, CVaR, or MTS are more risk-aware.\n- **Communicate distributions, not single numbers**: Show HDIs/quantiles and probabilities (e.g., P(ROAS ‚â• target)). It's better to understand the full spectrum of possibilities than to follow single numbers and be short-sighted.\n- **Define a region of practical equivalence (ROPE)**: Once you are comfortable with the uncertainty, play with ROPEs and find out how much you could lighten the estimated answer, and if you will do anything different if this one change under a range of values.\n\n# üöß Limitations\n- This approach represents the model‚Äôs confidence, but models can be very certain about a wrong answer. Always add business knowledge and guardrails to keep recommendations realistic.\n\n# Conclusion\n\nHope this article was helpful to understand how to use Bayesian media mix models to optimize your media spend. Understand uncertanty it's a powerful tool to make better decisions, but it's not a silver bullet.\n\nThe current example is a simple one, real life applications are more complex and require more sophisticated models, risk functions, and complex optimization problems, where constraints and business knowledge are key.\n\nAt [PyMC Labs](https://www.pymc-labs.com/) we're building tools to make this process easier. If you're interested in learning more, explore the PyMC‚ÄëMarketing [Example Gallery](https://www.pymc-marketing.io/en/stable/gallery/gallery.html) and [API](https://www.pymc-marketing.io/en/stable/api/index.html), our [documentation](https://docs.pymc-marketing.com/) and [blog](https://www.pymc-labs.com/blog-posts).\n\nYou can get a 30 minutes free consultation with our team to discuss your specific needs and how we can help you.\n\n- 1:1 Session with me: [Book a call](https://calendar.app.google/vX9DziLkdMSAAszU8)\n- Discovery session with PyMC Labs team: [Book a call](https://www.pymc-labs.com/?utm_source=carlos_trujillo&utm_medium=pydata_berlin&utm_campaign=bayesian_mmm_article)\n\nThanks if you read this far!\n\n",
    "supporting": [
      "bayesian_models_and_risk_optimization_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"0d31392f57014b7a9349d23785cccfed\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"26c1f33922b444f9bee9529ba97efbba\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"357a3e62225d4681832a352d68ff5a73\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"59c5c13bb940459cb77f52a0b3a92ba0\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_357a3e62225d4681832a352d68ff5a73\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"6a372b8c035d407b8221e420ddcc9412\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"7106674b48074ab68abc743daaaedb91\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_6a372b8c035d407b8221e420ddcc9412\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"81bc049f3fa54fa48d7e643b1cc61a0e\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"a29ec3ab594c4dccab6d509e20f03cbe\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_0d31392f57014b7a9349d23785cccfed\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Computing ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00\\n</pre>\\n\",\"text/plain\":\"Computing ... \\u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"b1038c311b09450088b9990665f61a51\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_26c1f33922b444f9bee9529ba97efbba\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"cfbd25131892493b82d4ca03289ffcf5\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_81bc049f3fa54fa48d7e643b1cc61a0e\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}